{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#VI-EN Machine Translation using BERT-to-GPT2 Model\n",
        "##AI VIETNAM\n",
        "**Dataset: IWSLT15-en-vi**\n",
        "\n",
        "**thai.nq07@gmail.com**"
      ],
      "metadata": {
        "id": "cnLHJ9PkahlQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcDsZmHz9tHh",
        "outputId": "014f6b14-5630-42f6-d813-4435ada456d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO8lLBysFx4w",
        "outputId": "8a846715-3810-49c0-9d40-55fae5757cc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Transformer\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/Transformer\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vs7gB9toNMg",
        "outputId": "6243bece-e95a-46f1-ee15-4bf26534250c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz6JwxbK0mo1"
      },
      "source": [
        "##1.Install library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfXCevuj97q9",
        "outputId": "96b2c442-37e2-4326-c906-127eb12b5c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install 'datasets==2.9.0' 'sentencepiece==0.1.99' 'sacrebleu==2.3.1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iOoEexf43Vqk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "import copy\n",
        "import heapq\n",
        "import datetime\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "import sacrebleu\n",
        "\n",
        "import datasets\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'numpy version: {np.__version__}')\n",
        "print(f'sacrebleu version: {sacrebleu.__version__}')\n",
        "print(f'datasets version: {datasets.__version__}')\n",
        "print(f'sentencepiece version: {spm.__version__}')\n",
        "print(f'torch version: {torch.__version__}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsMvUinwkySQ",
        "outputId": "282ec219-17da-4f3f-a898-122c02757df2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy version: 1.23.5\n",
            "sacrebleu version: 2.3.1\n",
            "datasets version: 2.9.0\n",
            "sentencepiece version: 0.1.99\n",
            "torch version: 2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5dJZutw0rug"
      },
      "source": [
        "##2.Data Preparing\n",
        "**IWSLT2015-EN-VI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Moxz37xr-QgU"
      },
      "outputs": [],
      "source": [
        "class DataPreparing:\n",
        "    def __init__(self, save_data_dir, source_lang, target_lang):\n",
        "        self.save_data_dir = save_data_dir\n",
        "        self.source_lang = source_lang\n",
        "        self.target_lang = target_lang\n",
        "\n",
        "    def download_dataset(self):\n",
        "        if not(os.path.exists(self.save_data_dir)):\n",
        "            print('Create Foler')\n",
        "            os.mkdir(self.save_data_dir)\n",
        "        if len(os.listdir(self.save_data_dir)) ==0:\n",
        "            print('#1-Download Dataset')\n",
        "            corpus = datasets.load_dataset(\"mt_eng_vietnamese\", \"iwslt2015-en-vi\")\n",
        "\n",
        "            print('#2-Save Dataset')\n",
        "            for data in ['train', 'validation', 'test']:\n",
        "\n",
        "                source_data, target_data = self.get_data(corpus[data])\n",
        "\n",
        "                print('Source lang: {} - {}: {}'.format(self.source_lang, data, len(source_data)))\n",
        "                print('Target lang: {} - {}: {}'.format(self.target_lang, data, len(target_data)))\n",
        "\n",
        "                self.save_data(source_data, os.path.join(self.save_data_dir, data + '.' + self.source_lang))\n",
        "                self.save_data(target_data, os.path.join(self.save_data_dir, data + '.' + self.target_lang))\n",
        "\n",
        "        else:\n",
        "            print('Dataset exit!')\n",
        "\n",
        "    def get_data(self, corpus):\n",
        "        source_data = []\n",
        "        target_data = []\n",
        "        for data in corpus:\n",
        "            source_data.append(data['translation'][self.source_lang])\n",
        "            target_data.append(data['translation'][self.target_lang])\n",
        "        return source_data, target_data\n",
        "\n",
        "    def save_data(self, data, save_path):\n",
        "        print('=> Save data => Path: {}'.format(save_path))\n",
        "        with open(save_path, 'w', encoding='utf-8') as f:\n",
        "            f.write('\\n'.join(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9YpHW5Y04aB"
      },
      "source": [
        "##3.SentencePiece Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "x_fHQHeU_4Zp"
      },
      "outputs": [],
      "source": [
        "def train_sentencepiece(cfg, is_src=True):\n",
        "    template = \"--input={} \\\n",
        "                --pad_id={} \\\n",
        "                --bos_id={} \\\n",
        "                --eos_id={} \\\n",
        "                --unk_id={} \\\n",
        "                --model_prefix={} \\\n",
        "                --vocab_size={} \\\n",
        "                --character_coverage={} \\\n",
        "                --model_type={}\"\n",
        "\n",
        "    if is_src:\n",
        "        train_file = f\"{cfg.data_dir}/train.{cfg.src_lang}\"\n",
        "        model_prefix = f\"{cfg.sp_dir}/{cfg.src_model_prefix}\"\n",
        "    else:\n",
        "        train_file = f\"{cfg.data_dir}/train.{cfg.tgt_lang}\"\n",
        "        model_prefix = f\"{cfg.sp_dir}/{cfg.tgt_model_prefix}\"\n",
        "\n",
        "    print(f\"===> Processing file: {train_file}\")\n",
        "    if not os.path.isdir(cfg.sp_dir):\n",
        "        os.mkdir(cfg.sp_dir)\n",
        "\n",
        "    sp_cfg = template.format(\n",
        "        train_file, # file txt gồm các câu ở mỗi dòng\n",
        "        cfg.pad_id, # index của token padding\n",
        "        cfg.sos_id, # index của token start of sentence\n",
        "        cfg.eos_id, # index của token end of sentence\n",
        "        cfg.unk_id, # index của token unknow\n",
        "        model_prefix, # tên của model tokenize sau khi train\n",
        "        cfg.sp_vocab_size, # kích thước bộ từ vựng (ở đây được đặt là 10k)\n",
        "        cfg.character_coverage, # tỉ lệ số lượng kí tự được mô hình sử dụng\n",
        "        cfg.model_type) # được đặt là \"unigram\" -> tokenize ở mức độ từ đơn\n",
        "\n",
        "    spm.SentencePieceTrainer.Train(sp_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM31YJgZ1K8U"
      },
      "source": [
        "##4.Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZnXQ_jD61pgl"
      },
      "outputs": [],
      "source": [
        "class NMTDataset(Dataset):\n",
        "    def __init__(self, cfg, data_type=\"train\"):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.sp_src, self.sp_tgt = self.load_sp_tokenizer()\n",
        "        self.src_texts, self.tgt_texts = self.read_data(data_type)\n",
        "\n",
        "        src_tokenized_sequences = self.texts_to_sequences(self.src_texts, True)\n",
        "        tgt_input_tokenized_sequences, tgt_output_tokenized_sequences = self.texts_to_sequences(self.tgt_texts, False)\n",
        "\n",
        "        self.src_data = torch.LongTensor(src_tokenized_sequences)\n",
        "        self.input_tgt_data = torch.LongTensor(tgt_input_tokenized_sequences)\n",
        "        self.output_tgt_data = torch.LongTensor(tgt_output_tokenized_sequences)\n",
        "\n",
        "    def read_data(self, data_type):\n",
        "        print(f\"===> Load data from: {self.cfg.data_dir}/{data_type}.{self.cfg.src_lang}\")\n",
        "        with open(f\"{self.cfg.data_dir}/{data_type}.{self.cfg.src_lang}\", 'r') as f:\n",
        "            src_texts = f.readlines()\n",
        "\n",
        "        print(f\"===> Load data from: {self.cfg.data_dir}/{data_type}.{self.cfg.tgt_lang}\")\n",
        "        with open(f\"{self.cfg.data_dir}/{data_type}.{self.cfg.tgt_lang}\", 'r') as f:\n",
        "            trg_texts = f.readlines()\n",
        "\n",
        "        return src_texts, trg_texts\n",
        "\n",
        "    def load_sp_tokenizer(self):\n",
        "        sp_src = spm.SentencePieceProcessor()\n",
        "        sp_src.Load(f\"{self.cfg.sp_dir}/{self.cfg.src_model_prefix}.model\")\n",
        "\n",
        "        sp_tgt = spm.SentencePieceProcessor()\n",
        "        sp_tgt.Load(f\"{self.cfg.sp_dir}/{self.cfg.tgt_model_prefix}.model\")\n",
        "\n",
        "        return sp_src, sp_tgt\n",
        "\n",
        "    def texts_to_sequences(self, texts, is_src=True):\n",
        "        if is_src:\n",
        "            src_tokenized_sequences = []\n",
        "            for text in tqdm(texts):\n",
        "                tokenized = self.sp_src.EncodeAsIds(text.strip())\n",
        "                src_tokenized_sequences.append(\n",
        "                    pad_or_truncate([self.cfg.sos_id] + tokenized + [self.cfg.eos_id], self.cfg.seq_len, self.cfg.pad_id)\n",
        "                )\n",
        "            return src_tokenized_sequences\n",
        "        else:\n",
        "            tgt_input_tokenized_sequences = []\n",
        "            tgt_output_tokenized_sequences = []\n",
        "            for text in tqdm(texts):\n",
        "                tokenized = self.sp_tgt.EncodeAsIds(text.strip())\n",
        "                tgt_input = [self.cfg.sos_id] + tokenized\n",
        "                tgt_output = tokenized + [self.cfg.eos_id]\n",
        "                tgt_input_tokenized_sequences.append(pad_or_truncate(tgt_input, self.cfg.seq_len, self.cfg.pad_id))\n",
        "                tgt_output_tokenized_sequences.append(pad_or_truncate(tgt_output, self.cfg.seq_len, self.cfg.pad_id))\n",
        "\n",
        "            return tgt_input_tokenized_sequences, tgt_output_tokenized_sequences\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.src_data[idx], self.input_tgt_data[idx], self.output_tgt_data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return np.shape(self.src_data)[0]\n",
        "\n",
        "def pad_or_truncate(tokenized_sequence, seq_len, pad_id):\n",
        "    if len(tokenized_sequence) < seq_len:\n",
        "        left = seq_len - len(tokenized_sequence)\n",
        "        padding = [pad_id] * left\n",
        "        tokenized_sequence += padding\n",
        "    else:\n",
        "        tokenized_sequence = tokenized_sequence[:seq_len]\n",
        "    return tokenized_sequence\n",
        "\n",
        "def get_data_loader(cfg, data_type='train'):\n",
        "    dataset = NMTDataset(cfg, data_type)\n",
        "\n",
        "    if data_type == 'train':\n",
        "        shuffle = False\n",
        "    else:\n",
        "        shuffle = False\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=shuffle)\n",
        "\n",
        "    return dataset, dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvx0Mu7CmIfg"
      },
      "source": [
        "##5.Transformer Model\n",
        "Ref: https://pytorch.org/tutorials/beginner/translation_transformer.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ol7eNRBWmMID"
      },
      "outputs": [],
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, drop_out=0.1):\n",
        "        super().__init__()\n",
        "        self.inf = 1e9\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        # W^Q, W^K, W^V in the paper\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(drop_out)\n",
        "        self.attn_softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "        # Final output linear transformation\n",
        "        self.w_0 = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        input_shape = q.shape\n",
        "\n",
        "        # Linear calculation +  split into num_heads\n",
        "        q = self.w_q(q).view(input_shape[0], -1, self.num_heads, self.d_k) # (B, L, num_heads, d_k)\n",
        "        k = self.w_k(k).view(input_shape[0], -1, self.num_heads, self.d_k) # (B, L, num_heads, d_k)\n",
        "        v = self.w_v(v).view(input_shape[0], -1, self.num_heads, self.d_k) # (B, L, num_heads, d_k)\n",
        "\n",
        "        # For convenience, convert all tensors in size (B, num_heads, L, d_k)\n",
        "        q = q.transpose(1, 2)\n",
        "        k = k.transpose(1, 2)\n",
        "        v = v.transpose(1, 2)\n",
        "\n",
        "        # Conduct self-attention\n",
        "        attn_values = self.self_attention(q, k, v, mask=mask) # (B, num_heads, L, d_k)\n",
        "        concat_output = attn_values.transpose(1, 2)\\\n",
        "            .contiguous().view(input_shape[0], -1, self.d_model) # (B, L, d_model)\n",
        "\n",
        "        return self.w_0(concat_output)\n",
        "\n",
        "    def self_attention(self, q, k, v, mask=None):\n",
        "        # Calculate attention scores with scaled dot-product attention\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) # (B, num_heads, L, L)\n",
        "        attn_scores = attn_scores / math.sqrt(self.d_k)\n",
        "\n",
        "        # If there is a mask, make masked spots -INF\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1) # (B, 1, L) => (B, 1, 1, L) or (B, L, L) => (B, 1, L, L)\n",
        "            attn_scores = attn_scores.masked_fill_(mask == 0, -1 * self.inf)\n",
        "\n",
        "        # Softmax and multiplying K to calculate attention value\n",
        "        attn_distribs = self.attn_softmax(attn_scores)\n",
        "\n",
        "        attn_distribs = self.dropout(attn_distribs)\n",
        "        attn_values = torch.matmul(attn_distribs, v) # (B, num_heads, L, d_k)\n",
        "\n",
        "        return attn_values\n",
        "\n",
        "class FeedFowardLayer(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, drop_out=0.1):\n",
        "        super().__init__()\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff, bias=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model, bias=True)\n",
        "        self.dropout = nn.Dropout(drop_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.linear_1(x)) # (B, L, d_ff)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear_2(x) # (B, L, d_model)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, d_model, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.layer = nn.LayerNorm([d_model], elementwise_affine=True, eps=self.eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, seq_len, d_model, device):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.d_model = d_model\n",
        "        # Make initial positional encoding matrix with 0\n",
        "        pe_matrix= torch.zeros(seq_len, d_model) # (L, d_model)\n",
        "\n",
        "        # Calculating position encoding values\n",
        "        for pos in range(seq_len):\n",
        "            for i in range(d_model):\n",
        "                if i % 2 == 0:\n",
        "                    pe_matrix[pos, i] = math.sin(pos / (10000 ** (2 * i / d_model)))\n",
        "                elif i % 2 == 1:\n",
        "                    pe_matrix[pos, i] = math.cos(pos / (10000 ** (2 * i / d_model)))\n",
        "\n",
        "        pe_matrix = pe_matrix.unsqueeze(0) # (1, L, d_model)\n",
        "        self.positional_encoding = pe_matrix.to(device=device).requires_grad_(False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * math.sqrt(self.d_model) # (B, L, d_model)\n",
        "        x = x + self.positional_encoding # (B, L, d_model)\n",
        "\n",
        "        return x\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, drop_out=0.1):\n",
        "        super().__init__()\n",
        "        self.layer_norm_1 = LayerNormalization(d_model)\n",
        "        self.multihead_attention = MultiheadAttention(d_model, num_heads, drop_out)\n",
        "        self.drop_out_1 = nn.Dropout(drop_out)\n",
        "\n",
        "        self.layer_norm_2 = LayerNormalization(d_model)\n",
        "        self.feed_forward = FeedFowardLayer(d_model, d_ff, drop_out)\n",
        "        self.drop_out_2 = nn.Dropout(drop_out)\n",
        "\n",
        "    def forward(self, x, e_mask):\n",
        "        x_1 = self.layer_norm_1(x) # (B, L, d_model)\n",
        "        x = x + self.drop_out_1(\n",
        "            self.multihead_attention(x_1, x_1, x_1, mask=e_mask)\n",
        "        ) # (B, L, d_model)\n",
        "\n",
        "        x_2 = self.layer_norm_2(x) # (B, L, d_model)\n",
        "        x = x + self.drop_out_2(self.feed_forward(x_2)) # (B, L, d_model)\n",
        "\n",
        "        return x # (B, L, d_model)\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, drop_out=0.1):\n",
        "        super().__init__()\n",
        "        self.layer_norm_1 = LayerNormalization(d_model)\n",
        "        self.masked_multihead_attention = MultiheadAttention(d_model, num_heads, drop_out)\n",
        "        self.drop_out_1 = nn.Dropout(drop_out)\n",
        "\n",
        "        self.layer_norm_2 = LayerNormalization(d_model)\n",
        "        self.multihead_attention = MultiheadAttention(d_model, num_heads, drop_out)\n",
        "        self.drop_out_2 = nn.Dropout(drop_out)\n",
        "\n",
        "        self.layer_norm_3 = LayerNormalization(d_model)\n",
        "        self.feed_forward = FeedFowardLayer(d_model, d_ff, drop_out)\n",
        "        self.drop_out_3 = nn.Dropout(drop_out)\n",
        "\n",
        "    def forward(self, x, e_output, e_mask,  d_mask):\n",
        "        x_1 = self.layer_norm_1(x) # (B, L, d_model)\n",
        "        x = x + self.drop_out_1(\n",
        "            self.masked_multihead_attention(x_1, x_1, x_1, mask=d_mask)\n",
        "        ) # (B, L, d_model)\n",
        "        x_2 = self.layer_norm_2(x) # (B, L, d_model)\n",
        "        x = x + self.drop_out_2(\n",
        "            self.multihead_attention(x_2, e_output, e_output, mask=e_mask)\n",
        "        ) # (B, L, d_model)\n",
        "        x_3 = self.layer_norm_3(x) # (B, L, d_model)\n",
        "        x = x + self.drop_out_3(self.feed_forward(x_3)) # (B, L, d_model)\n",
        "\n",
        "        return x # (B, L, d_model)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, d_ff, drop_out=0.1):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.layers = nn.ModuleList(\n",
        "            [EncoderLayer(d_model, num_heads, d_ff, drop_out) for i in range(num_layers)]\n",
        "        )\n",
        "        self.layer_norm = LayerNormalization(d_model)\n",
        "\n",
        "    def forward(self, x, e_mask):\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.layers[i](x, e_mask)\n",
        "\n",
        "        return self.layer_norm(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, d_ff, drop_out):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.layers = nn.ModuleList(\n",
        "            [DecoderLayer(d_model, num_heads, d_ff, drop_out) for i in range(num_layers)]\n",
        "        )\n",
        "        self.layer_norm = LayerNormalization(d_model)\n",
        "\n",
        "    def forward(self, x, e_output, e_mask, d_mask):\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.layers[i](x, e_output, e_mask, d_mask)\n",
        "\n",
        "        return self.layer_norm(x)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.src_embedding = nn.Embedding(self.cfg.sp_vocab_size, self.cfg.d_model)\n",
        "        self.tgt_embedding = nn.Embedding(self.cfg.sp_vocab_size, self.cfg.d_model)\n",
        "        self.positional_encoder = PositionalEncoder(\n",
        "            self.cfg.seq_len,\n",
        "            self.cfg.d_model,\n",
        "            self.cfg.device\n",
        "        )\n",
        "        self.encoder = Encoder(\n",
        "            self.cfg.num_layers,\n",
        "            self.cfg.d_model,\n",
        "            self.cfg.num_heads,\n",
        "            self.cfg.d_ff,\n",
        "            self.cfg.drop_out\n",
        "        )\n",
        "        self.decoder = Decoder(\n",
        "            self.cfg.num_layers,\n",
        "            self.cfg.d_model,\n",
        "            self.cfg.num_heads,\n",
        "            self.cfg.d_ff,\n",
        "            self.cfg.drop_out\n",
        "        )\n",
        "        self.output_linear = nn.Linear(self.cfg.d_model, self.cfg.sp_vocab_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, src_input, tgt_input, e_mask=None, d_mask=None):\n",
        "        src_input = self.src_embedding(src_input) # (B, L) => (B, L, d_model)\n",
        "        tgt_input = self.tgt_embedding(tgt_input) # (B, L) => (B, L, d_model)\n",
        "        src_input = self.positional_encoder(src_input) # (B, L, d_model) => (B, L, d_model)\n",
        "        tgt_input = self.positional_encoder(tgt_input) # (B, L, d_model) => (B, L, d_model)\n",
        "\n",
        "        e_output = self.encoder(src_input, e_mask) # (B, L, d_model)\n",
        "        d_output = self.decoder(tgt_input, e_output, e_mask, d_mask) # (B, L, d_model)\n",
        "\n",
        "        output = self.softmax(self.output_linear(d_output)) # (B, L, d_model) => # (B, L, trg_vocab_size)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUUJaH8GovIj"
      },
      "source": [
        "##7.Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mcCFypjcowwr"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, cfg, is_train=True, load_ckpt=True):\n",
        "        self.cfg = cfg\n",
        "\n",
        "        print(\"Loading Transformer model & Adam optimizer...\")\n",
        "        self.model = Transformer(self.cfg).to(self.cfg.device)\n",
        "\n",
        "        self.optim = torch.optim.Adam(self.model.parameters(), lr=self.cfg.learning_rate)\n",
        "\n",
        "        self.best_loss = 100.0\n",
        "        if load_ckpt:\n",
        "            print(\"Loading checkpoint...\")\n",
        "            checkpoint = torch.load(f\"{self.cfg.ckpt_dir}/{self.cfg.ckpt_name}\", map_location=self.cfg.device)\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.optim.load_state_dict(checkpoint['optim_state_dict'])\n",
        "            self.best_loss = checkpoint['loss']\n",
        "        else:\n",
        "            print(\"Initializing the model...\")\n",
        "            for p in self.model.parameters():\n",
        "                if p.dim() > 1:\n",
        "                    nn.init.xavier_uniform_(p)\n",
        "\n",
        "        # Prepare Tokenizer\n",
        "        self.prepare_tokenizer()\n",
        "\n",
        "        if is_train:\n",
        "            # Load loss function\n",
        "            print(\"Loading loss function...\")\n",
        "            self.criterion = nn.NLLLoss()\n",
        "\n",
        "            # Load dataloaders\n",
        "            print(\"Loading dataloaders...\")\n",
        "            self.train_dataset, self.train_loader = get_data_loader(self.cfg, 'train')\n",
        "            self.valid_dataset, self.valid_loader = get_data_loader(self.cfg, 'validation')\n",
        "\n",
        "        else:\n",
        "            if os.path.exists(f\"{self.cfg.ckpt_dir}/{self.cfg.ckpt_name}\"):\n",
        "                print(\"Loading sentencepiece tokenizer...\")\n",
        "                self.sp_src = spm.SentencePieceProcessor()\n",
        "                self.sp_tgt = spm.SentencePieceProcessor()\n",
        "                self.sp_src.Load(f\"{self.cfg.sp_dir}/{self.cfg.src_model_prefix}.model\")\n",
        "                self.sp_tgt.Load(f\"{self.cfg.sp_dir}/{self.cfg.tgt_model_prefix}.model\")\n",
        "            else:\n",
        "                print(\"Checkpoint path not exits...\")\n",
        "\n",
        "        print(\"Setting finished.\")\n",
        "\n",
        "    def prepare_tokenizer(self):\n",
        "        if not os.path.isdir(self.cfg.sp_dir):\n",
        "            print('Training sentencepiece tokenizer...')\n",
        "            train_sentencepiece(self.cfg, is_src=True)\n",
        "            train_sentencepiece(self.cfg, is_src=False)\n",
        "        else:\n",
        "            print('Tokenization already...')\n",
        "\n",
        "    def train(self):\n",
        "        print(\"Training...\")\n",
        "\n",
        "        for epoch in range(1, self.cfg.num_epochs+1):\n",
        "            print(f\"#################### Epoch: {epoch} ####################\")\n",
        "\n",
        "            self.model.train()\n",
        "            train_losses = []\n",
        "            start_time = datetime.datetime.now()\n",
        "\n",
        "            bar = tqdm(enumerate(self.train_loader), total=len(self.train_loader), desc='TRAINING')\n",
        "\n",
        "            for batch_idx, batch in bar:\n",
        "                src_input, tgt_input, tgt_output = batch\n",
        "                src_input, tgt_input, tgt_output = src_input.to(self.cfg.device), tgt_input.to(self.cfg.device), tgt_output.to(self.cfg.device)\n",
        "\n",
        "                e_mask, d_mask = self.create_mask(src_input, tgt_input) #\n",
        "\n",
        "                logits = self.model(src_input, tgt_input, e_mask, d_mask)\n",
        "\n",
        "                self.optim.zero_grad()\n",
        "\n",
        "                loss = self.criterion(\n",
        "                    logits.view(-1, logits.shape[-1]),\n",
        "                    tgt_output.reshape(-1)\n",
        "                )\n",
        "\n",
        "                loss.backward()\n",
        "                self.optim.step()\n",
        "\n",
        "                train_losses.append(loss.item())\n",
        "\n",
        "                del src_input, tgt_input, tgt_output, e_mask, d_mask, logits\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                bar.set_postfix(TRAIN=\"Epoch {} - Batch_Loss {:.2f} - Train_Loss {:.2f} - Best_Valid_Loss {:.2f}\".format(\n",
        "                    epoch,\n",
        "                    loss.item(),\n",
        "                    np.mean(train_losses),\n",
        "                    self.best_loss\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            end_time = datetime.datetime.now()\n",
        "            training_time = end_time - start_time\n",
        "\n",
        "            mean_train_loss = np.mean(train_losses)\n",
        "            print(f\"Train loss: {mean_train_loss} || Time: {training_time} secs\")\n",
        "\n",
        "            valid_loss, valid_time = self.validation()\n",
        "\n",
        "            if valid_loss < self.best_loss:\n",
        "                if not os.path.exists(self.cfg.ckpt_dir):\n",
        "                    os.mkdir(self.cfg.ckpt_dir)\n",
        "\n",
        "                self.best_loss = valid_loss\n",
        "                state_dict = {\n",
        "                    'model_state_dict': self.model.state_dict(),\n",
        "                    'optim_state_dict': self.optim.state_dict(),\n",
        "                    'loss': self.best_loss\n",
        "                }\n",
        "                torch.save(state_dict, f\"{self.cfg.ckpt_dir}/{self.cfg.ckpt_name}\")\n",
        "                print(f\"***** Current best checkpoint is saved. *****\")\n",
        "\n",
        "            print(f\"Best valid loss: {self.best_loss}\")\n",
        "            print(f\"Valid loss: {valid_loss} || One epoch training time: {valid_time}\")\n",
        "\n",
        "        print(f\"Training finished!\")\n",
        "\n",
        "    def validation(self):\n",
        "        self.model.eval()\n",
        "\n",
        "        valid_losses = []\n",
        "        start_time = datetime.datetime.now()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            bar = tqdm(enumerate(self.valid_loader), total=len(self.valid_loader), desc='VALIDATIION')\n",
        "            for batch_idx, batch in bar:\n",
        "                src_input, tgt_input, tgt_output = batch\n",
        "                src_input, tgt_input, tgt_output = src_input.to(self.cfg.device), tgt_input.to(self.cfg.device), tgt_output.to(self.cfg.device)\n",
        "\n",
        "                e_mask, d_mask = self.create_mask(src_input, tgt_input)\n",
        "\n",
        "                logits = self.model(src_input, tgt_input, e_mask, d_mask)\n",
        "\n",
        "                loss = self.criterion(\n",
        "                    logits.view(-1, logits.shape[-1]),\n",
        "                    tgt_output.reshape(-1)\n",
        "                )\n",
        "\n",
        "                valid_losses.append(loss.item())\n",
        "\n",
        "                bar.set_postfix(TRAIN=\"Batch_Loss {:.2f} - Valid_Loss {:.2f}\".format(\n",
        "                    loss.item(),\n",
        "                    np.mean(valid_losses)\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                del src_input, tgt_input, tgt_output, e_mask, d_mask, logits\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        end_time = datetime.datetime.now()\n",
        "        validation_time = end_time - start_time\n",
        "\n",
        "        mean_valid_loss = np.mean(valid_losses)\n",
        "\n",
        "        return mean_valid_loss, f\"{validation_time} secs\"\n",
        "\n",
        "    def inference(self, input_sentence):\n",
        "        self.model.eval()\n",
        "\n",
        "        print(\"Preprocessing input sentence...\")\n",
        "        tokenized = self.sp_src.EncodeAsIds(input_sentence)\n",
        "        src_data = torch.LongTensor(\n",
        "            pad_or_truncate([self.cfg.sos_id] + tokenized + [self.cfg.eos_id], self.cfg.seq_len, self.cfg.pad_id)\n",
        "        ).unsqueeze(0).to(self.cfg.device)\n",
        "\n",
        "        e_mask = (src_data != self.cfg.pad_id).unsqueeze(1).to(self.cfg.device) # (1, 1, L)\n",
        "\n",
        "        start_time = datetime.datetime.now()\n",
        "\n",
        "        print(\"Encoding input sentence...\")\n",
        "        src_data = self.model.src_embedding(src_data)\n",
        "        src_data = self.model.positional_encoder(src_data)\n",
        "        e_output = self.model.encoder(src_data, e_mask) # (1, L, d_model)\n",
        "\n",
        "        result = self.greedy_search(e_output, e_mask)\n",
        "\n",
        "        end_time = datetime.datetime.now()\n",
        "\n",
        "        total_inference_time = end_time - start_time\n",
        "\n",
        "        print(f\"Input: {input_sentence}\")\n",
        "        print(f\"Result: {result}\")\n",
        "        print(f\"Inference finished! || Total inference time: {total_inference_time}secs\")\n",
        "        return result\n",
        "\n",
        "    def greedy_search(self, e_output, e_mask):\n",
        "        last_words = torch.LongTensor([self.cfg.pad_id] * self.cfg.seq_len).to(self.cfg.device) # (L)\n",
        "        last_words[0] = self.cfg.sos_id # (L)\n",
        "        cur_len = 1\n",
        "\n",
        "        for i in range(self.cfg.seq_len):\n",
        "            d_mask = (last_words.unsqueeze(0) != self.cfg.pad_id).unsqueeze(1).to(self.cfg.device) # (1, 1, L)\n",
        "            nopeak_mask = torch.ones([1, self.cfg.seq_len, self.cfg.seq_len], dtype=torch.bool).to(self.cfg.device)  # (1, L, L)\n",
        "            nopeak_mask = torch.tril(nopeak_mask)  # (1, L, L) to triangular shape\n",
        "            d_mask = d_mask & nopeak_mask  # (1, L, L) padding false\n",
        "\n",
        "            tgt_embedded = self.model.tgt_embedding(last_words.unsqueeze(0))\n",
        "            tgt_positional_encoded = self.model.positional_encoder(tgt_embedded)\n",
        "            decoder_output = self.model.decoder(\n",
        "                tgt_positional_encoded,\n",
        "                e_output,\n",
        "                e_mask,\n",
        "                d_mask\n",
        "            ) # (1, L, d_model)\n",
        "\n",
        "            output = self.model.softmax(\n",
        "                self.model.output_linear(decoder_output)\n",
        "            ) # (1, L, trg_vocab_size)\n",
        "\n",
        "            output = torch.argmax(output, dim=-1) # (1, L)\n",
        "            last_word_id = output[0][i].item()\n",
        "\n",
        "            if i < self.cfg.seq_len-1:\n",
        "                last_words[i+1] = last_word_id\n",
        "                cur_len += 1\n",
        "\n",
        "            if last_word_id == self.cfg.eos_id:\n",
        "                break\n",
        "\n",
        "        if last_words[-1].item() == self.cfg.pad_id:\n",
        "            decoded_output = last_words[1:cur_len].tolist()\n",
        "        else:\n",
        "            decoded_output = last_words[1:].tolist()\n",
        "        decoded_output = self.sp_tgt.decode_ids(decoded_output)\n",
        "\n",
        "        return decoded_output\n",
        "\n",
        "    def create_mask(self, src_input, tgt_input):\n",
        "        e_mask = (src_input != self.cfg.pad_id).unsqueeze(1)  # (B, 1, L)\n",
        "        d_mask = (tgt_input != self.cfg.pad_id).unsqueeze(1)  # (B, 1, L)\n",
        "\n",
        "        nopeak_mask = torch.ones([1, self.cfg.seq_len, self.cfg.seq_len], dtype=torch.bool)  # (1, L, L)\n",
        "        nopeak_mask = torch.tril(nopeak_mask).to(self.cfg.device)  # (1, L, L) to triangular shape\n",
        "        d_mask = d_mask & nopeak_mask  # (B, L, L) padding false\n",
        "\n",
        "        return e_mask, d_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pqIEejha7tt"
      },
      "source": [
        "##8.Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CmX2WOFqrpQ-"
      },
      "outputs": [],
      "source": [
        "class BaseConfig:\n",
        "    \"\"\" base Encoder Decoder config \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "class NMTConfig(BaseConfig):\n",
        "    # Dataset\n",
        "    data_dir = './transformer/data'\n",
        "    # data_dir = '/content/test_download_data/data'\n",
        "    src_lang = 'vi'\n",
        "    tgt_lang = 'en'\n",
        "\n",
        "    # Tokenizer\n",
        "    sp_dir = data_dir + '/sp'\n",
        "    pad_id = 0\n",
        "    sos_id = 1\n",
        "    eos_id = 2\n",
        "    unk_id = 3\n",
        "    src_model_prefix = 'sp_' + src_lang\n",
        "    tgt_model_prefix = 'sp_' + tgt_lang\n",
        "    sp_vocab_size = 10000\n",
        "    character_coverage = 1.0\n",
        "    model_type = 'unigram'\n",
        "\n",
        "    # Model\n",
        "    num_heads = 8\n",
        "    num_layers = 6\n",
        "    d_model = 512\n",
        "    d_ff = 2048\n",
        "    drop_out = 0.1\n",
        "\n",
        "    # Training\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    learning_rate = 1e-4\n",
        "    batch_size = 64\n",
        "    seq_len = 150\n",
        "    num_epochs = 2\n",
        "    ckpt_dir = './transformer'\n",
        "    ckpt_name = 'best_ckpt.tar'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r '/content/test_download_data'"
      ],
      "metadata": {
        "id": "eaQSz-m0RLnZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir '/content/test_download_data/'\n",
        "# !mkdir '/content/test_download_data/data'"
      ],
      "metadata": {
        "id": "Ie-FSpqlRH6X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wVmHNIxks6z-"
      },
      "outputs": [],
      "source": [
        "cfg = NMTConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JxLSAsdbtD7j"
      },
      "outputs": [],
      "source": [
        "# data_pre = DataPreparing(cfg.data_dir, cfg.src_lang, cfg.tgt_lang)\n",
        "# data_pre.download_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6K7bBbwvimSU"
      },
      "outputs": [],
      "source": [
        "# trainer = Trainer(cfg, is_train=True, load_ckpt=False)\n",
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9.Evaluate"
      ],
      "metadata": {
        "id": "kYCzZKoHgg8l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "YWU5ZRnOTPuG",
        "outputId": "e9ed6886-148f-411f-acb3-bc28a0725371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy version: 1.23.5\n",
            "datasets version: 2.9.0\n",
            "sentencepiece version: 0.1.99\n",
            "torch version: 2.1.0+cu121\n",
            "\n",
            "\n",
            "Loading Transformer model & Adam optimizer...\n",
            "Loading checkpoint...\n",
            "Tokenization already...\n",
            "Loading sentencepiece tokenizer...\n",
            "Setting finished.\n",
            "Preprocessing input sentence...\n",
            "Encoding input sentence...\n",
            "Input: Tôi yêu bạn.\n",
            "Result: I love you .\n",
            "Inference finished! || Total inference time: 0:00:05.059223secs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I love you .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "print(f'numpy version: {np.__version__}')\n",
        "print(f'datasets version: {datasets.__version__}')\n",
        "print(f'sentencepiece version: {spm.__version__}')\n",
        "print(f'torch version: {torch.__version__}')\n",
        "print(\"\\n\")\n",
        "cfg = NMTConfig()\n",
        "trainer = Trainer(cfg, is_train=False, load_ckpt=True)\n",
        "trainer.inference('Tôi yêu bạn.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-fc-AWP5E_G",
        "outputId": "c456a3fb-26f2-412c-bb11-1aead4cae6d3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(cfg, trainer):\n",
        "    with open(cfg.data_dir + '/test.' + cfg.src_lang, 'r') as f:\n",
        "        src_texts = f.readlines()\n",
        "    src_texts = [s.strip() for s in src_texts]\n",
        "\n",
        "    with open(cfg.data_dir + '/test.' + cfg.tgt_lang, 'r') as f:\n",
        "        tgt_texts = f.readlines()\n",
        "    tgt_texts = [s.strip() for s in tgt_texts]\n",
        "\n",
        "    len(src_texts) == len(tgt_texts)\n",
        "\n",
        "    pred_texts = []\n",
        "    for sent in tqdm(src_texts):\n",
        "        pred_texts.append(trainer.inference(sent))\n",
        "\n",
        "    bleu_score = sacrebleu.corpus_bleu(pred_texts, [tgt_texts], force=True)\n",
        "\n",
        "    return pred_texts, bleu_score"
      ],
      "metadata": {
        "id": "Tffao98NnBGK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_texts, bleu_score = evaluate(cfg, trainer)"
      ],
      "metadata": {
        "id": "qjLFYiSPn_8n"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bleu_score"
      ],
      "metadata": {
        "id": "q_Tp22HEcCDt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training step by step**"
      ],
      "metadata": {
        "id": "MCDZODrl1WJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load data**"
      ],
      "metadata": {
        "id": "zlwnit86RL5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = NMTDataset(cfg=cfg, data_type=\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e_sO9Pz1XuZ",
        "outputId": "8c4f924d-d7ee-424f-99a8-4e9d508574f6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===> Load data from: ./transformer/data/train.vi\n",
            "===> Load data from: ./transformer/data/train.en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 133317/133317 [00:06<00:00, 20292.16it/s]\n",
            "100%|██████████| 133317/133317 [00:08<00:00, 15549.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data[0] # 13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cAi-_zi1o8l",
        "outputId": "6e4ce98a-3a9d-48f3-84ae-7ac92768bbf7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   1, 1960,   74,  128,  974,  146,    9,  418,  127,   41,  404,  817,\n",
              "            2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0]),\n",
              " tensor([   1, 6509, 3475, 1785,    4,   67,   48,  396,    4,  731,   13,  933,\n",
              "         3219,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0]),\n",
              " tensor([6509, 3475, 1785,    4,   67,   48,  396,    4,  731,   13,  933, 3219,\n",
              "            2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data[1] # 88"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTG_8NIwE0-D",
        "outputId": "3883982f-2d8e-46c1-aed5-89918e25c83d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   1,  373,   17,  692,  671,    4,  732,  150,  223,   74,  404, 1099,\n",
              "         3657, 1414, 2472,  106, 1301,  165, 1110, 1399,   41,   11, 1339,  303,\n",
              "          345,   74,  216, 1666,   39,   16,  128,  974,  146,   11,  418,  127,\n",
              "         1527,  972,   41,  351,  170,  404,  817,    4,  141,   29, 1386,  324,\n",
              "          250,   13,  102,   93,  195,  986,   19,   24,  275,   17,   62, 1454,\n",
              "           31,  281,  456,   23,   93,    9,  999,  504, 1571,  717,  155, 1033,\n",
              "          883,   40,  176,  578,  175,  154,   41,    9,  331,  427, 2015,   51,\n",
              "         1212,   35,    5,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0]),\n",
              " tensor([   1,  152, 2326,  582,    4,    5, 8927,  233, 5436, 6509, 3475, 1785,\n",
              "         1002,    6,   13, 4677,   14,    8, 1429, 1105, 1351,    4,  731,    8,\n",
              "         3056, 3219,    6,   38,  933,  175,    4,    5,   35,  176,  603,   40,\n",
              "           56,   14,  471,    6,   93, 2738,   31,   40,    4,  551,   13,  699,\n",
              "           19, 2055,  150,    8, 3747,   18, 4471,   14,  287,   38,   13,  812,\n",
              "          916,    7,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0]),\n",
              " tensor([ 152, 2326,  582,    4,    5, 8927,  233, 5436, 6509, 3475, 1785, 1002,\n",
              "            6,   13, 4677,   14,    8, 1429, 1105, 1351,    4,  731,    8, 3056,\n",
              "         3219,    6,   38,  933,  175,    4,    5,   35,  176,  603,   40,   56,\n",
              "           14,  471,    6,   93, 2738,   31,   40,    4,  551,   13,  699,   19,\n",
              "         2055,  150,    8, 3747,   18, 4471,   14,  287,   38,   13,  812,  916,\n",
              "            7,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data[2] # 34"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeUFez63E4xj",
        "outputId": "aabdfaea-1d35-4b02-9e66-bd08fd999555"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   1,   49,  100,   31,   25,   20,   83,   41,   33,  768,  139,   13,\n",
              "           11, 1339,  303,  345,   74,   24, 1138,  173,   36,  111,   25,  826,\n",
              "           17, 1691,   35,   20,  233,   64,   77,  524,    5,    2,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0]),\n",
              " tensor([   1,   17,   10,   12,    9,   31,   55,   11,  148,   11,   21,   11,\n",
              "          188,   46,    8,  854,   14,    8, 1105, 1351,   16,   99,  106,  114,\n",
              "            4,  337,    8, 3219,    6,   21,   88,   18,    8,  637,    7,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0]),\n",
              " tensor([  17,   10,   12,    9,   31,   55,   11,  148,   11,   21,   11,  188,\n",
              "           46,    8,  854,   14,    8, 1105, 1351,   16,   99,  106,  114,    4,\n",
              "          337,    8, 3219,    6,   21,   88,   18,    8,  637,    7,    2,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Init model, tokenizer, loss fn**"
      ],
      "metadata": {
        "id": "0bt8RXcSRSfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_tokenizer():\n",
        "    if not os.path.isdir(cfg.sp_dir):\n",
        "        print('Training sentencepiece tokenizer...')\n",
        "        train_sentencepiece(cfg, is_src=True)\n",
        "        train_sentencepiece(cfg, is_src=False)\n",
        "    else:\n",
        "        print('Tokenization already...')"
      ],
      "metadata": {
        "id": "Ic2HJuShP01-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading Transformer model & Adam optimizer...\")\n",
        "model = Transformer(cfg).to(cfg.device)\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate)\n",
        "\n",
        "best_loss = 100.0\n",
        "print(\"Loading checkpoint...\")\n",
        "checkpoint = torch.load(f\"{cfg.ckpt_dir}/{cfg.ckpt_name}\", map_location=cfg.device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optim.load_state_dict(checkpoint['optim_state_dict'])\n",
        "best_loss = checkpoint['loss']\n",
        "\n",
        "# Prepare Tokenizer\n",
        "prepare_tokenizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGvsIGRZM8dk",
        "outputId": "e7101723-ea44-4fef-f13e-e1de54c27790"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Transformer model & Adam optimizer...\n",
            "Loading checkpoint...\n",
            "Tokenization already...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataloader Train**"
      ],
      "metadata": {
        "id": "9cyJVfAURW-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load loss function\n",
        "print(\"Loading loss function...\")\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Load dataloaders\n",
        "print(\"Loading dataloaders...\")\n",
        "train_dataset, train_loader = get_data_loader(cfg, 'train')\n",
        "valid_dataset, valid_loader = get_data_loader(cfg, 'validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SMhMzdsRcbt",
        "outputId": "bd0fa5ed-eb6c-48c1-af74-9e075c22f94f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading loss function...\n",
            "Loading dataloaders...\n",
            "===> Load data from: ./transformer/data/train.vi\n",
            "===> Load data from: ./transformer/data/train.en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 133317/133317 [00:07<00:00, 17900.90it/s]\n",
            "100%|██████████| 133317/133317 [00:06<00:00, 20773.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===> Load data from: ./transformer/data/validation.vi\n",
            "===> Load data from: ./transformer/data/validation.en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1268/1268 [00:00<00:00, 23770.24it/s]\n",
            "100%|██████████| 1268/1268 [00:00<00:00, 23095.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL6KvaP8SLiF",
        "outputId": "31ab1e59-cd99-4197-873f-a4af3927b6ca"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (src_embedding): Embedding(10000, 512)\n",
              "  (tgt_embedding): Embedding(10000, 512)\n",
              "  (positional_encoder): PositionalEncoder()\n",
              "  (encoder): Encoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x EncoderLayer(\n",
              "        (layer_norm_1): LayerNormalization(\n",
              "          (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (multihead_attention): MultiheadAttention(\n",
              "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attn_softmax): Softmax(dim=-1)\n",
              "          (w_0): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (drop_out_1): Dropout(p=0.1, inplace=False)\n",
              "        (layer_norm_2): LayerNormalization(\n",
              "          (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): FeedFowardLayer(\n",
              "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (drop_out_2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm): LayerNormalization(\n",
              "      (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x DecoderLayer(\n",
              "        (layer_norm_1): LayerNormalization(\n",
              "          (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (masked_multihead_attention): MultiheadAttention(\n",
              "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attn_softmax): Softmax(dim=-1)\n",
              "          (w_0): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (drop_out_1): Dropout(p=0.1, inplace=False)\n",
              "        (layer_norm_2): LayerNormalization(\n",
              "          (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (multihead_attention): MultiheadAttention(\n",
              "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attn_softmax): Softmax(dim=-1)\n",
              "          (w_0): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (drop_out_2): Dropout(p=0.1, inplace=False)\n",
              "        (layer_norm_3): LayerNormalization(\n",
              "          (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): FeedFowardLayer(\n",
              "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (drop_out_3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm): LayerNormalization(\n",
              "      (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (output_linear): Linear(in_features=512, out_features=10000, bias=True)\n",
              "  (softmax): LogSoftmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []"
      ],
      "metadata": {
        "id": "bq-lvuTiUdRq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bar = tqdm(enumerate(train_loader), total=len(train_loader), desc='TRAINING')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFNBTrEaUd_Z",
        "outputId": "bbc7e3f3-dac1-4340-bccc-ca8b5f90d946"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTRAINING:   0%|          | 0/2084 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_input, tgt_input, tgt_output = _, _, _\n",
        "for batch_idx, batch in bar:\n",
        "    src_input, tgt_input, tgt_output = batch\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9CwKelaU0DB",
        "outputId": "2e801010-c2f0-42e0-9785-6e22995b6c0e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTRAINING:   0%|          | 0/2084 [00:00<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **src_input, tgt_input, tgt_output**"
      ],
      "metadata": {
        "id": "7HRg5tuTZbog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_input, tgt_input, tgt_output = src_input.to(cfg.device), tgt_input.to(cfg.device), tgt_output.to(cfg.device)"
      ],
      "metadata": {
        "id": "_DDs2j7ZVTlD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(src_input)\n",
        "print(src_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WjmoXb2Vik8",
        "outputId": "7dfd5fa5-0237-4fbf-a0bd-4358c81317f9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   1, 1960,   74,  ...,    0,    0,    0],\n",
            "        [   1,  373,   17,  ...,    0,    0,    0],\n",
            "        [   1,   49,  100,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [   1,  697,    4,  ...,    0,    0,    0],\n",
            "        [   1,  908,   19,  ...,    0,    0,    0],\n",
            "        [   1,  199,   43,  ...,    0,    0,    0]])\n",
            "torch.Size([64, 150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tgt_input)\n",
        "print(tgt_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg1AsyQjVt_B",
        "outputId": "8df43ee3-3422-44ab-d582-7992bb36bcaf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   1, 6509, 3475,  ...,    0,    0,    0],\n",
            "        [   1,  152, 2326,  ...,    0,    0,    0],\n",
            "        [   1,   17,   10,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [   1,  192,    4,  ...,    0,    0,    0],\n",
            "        [   1,  770, 5923,  ...,    0,    0,    0],\n",
            "        [   1,  107,   90,  ...,    0,    0,    0]])\n",
            "torch.Size([64, 150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tgt_output)\n",
        "print(tgt_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDl56gBDVvcs",
        "outputId": "f8cf06b0-c140-4dde-ceef-0f86d48246d7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6509, 3475, 1785,  ...,    0,    0,    0],\n",
            "        [ 152, 2326,  582,  ...,    0,    0,    0],\n",
            "        [  17,   10,   12,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 192,    4,    5,  ...,    0,    0,    0],\n",
            "        [ 770, 5923,    4,  ...,    0,    0,    0],\n",
            "        [ 107,   90,   11,  ...,    0,    0,    0]])\n",
            "torch.Size([64, 150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create mask**"
      ],
      "metadata": {
        "id": "5YzE45InYzgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask(src_input, tgt_input):\n",
        "    e_mask = (src_input != cfg.pad_id).unsqueeze(1)  # (B, 1, L)\n",
        "    d_mask = (tgt_input != cfg.pad_id).unsqueeze(1)  # (B, 1, L)\n",
        "\n",
        "    nopeak_mask = torch.ones([1, cfg.seq_len, cfg.seq_len], dtype=torch.bool)  # (1, L, L)\n",
        "    nopeak_mask = torch.tril(nopeak_mask).to(cfg.device)  # (1, L, L) to triangular shape\n",
        "    d_mask = d_mask & nopeak_mask  # (B, L, L) padding false\n",
        "\n",
        "    return e_mask, d_mask"
      ],
      "metadata": {
        "id": "W9LHb8jOZHgS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e_mask, d_mask = create_mask(src_input, tgt_input)"
      ],
      "metadata": {
        "id": "XF_qZvI1Y1pe"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(e_mask)\n",
        "print(e_mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta4g1rZUbzxr",
        "outputId": "5c0d4727-d2d6-475e-aa55-89c5ddadbc9b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ True,  True,  True,  ..., False, False, False]],\n",
            "\n",
            "        [[ True,  True,  True,  ..., False, False, False]],\n",
            "\n",
            "        [[ True,  True,  True,  ..., False, False, False]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ True,  True,  True,  ..., False, False, False]],\n",
            "\n",
            "        [[ True,  True,  True,  ..., False, False, False]],\n",
            "\n",
            "        [[ True,  True,  True,  ..., False, False, False]]])\n",
            "torch.Size([64, 1, 150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(e_mask[0]) # 13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPZdDyEzcDbi",
        "outputId": "d2dc08ea-a286-45cd-96d0-a89d4f9def73"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(e_mask[1]) # 88"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsuVmdzmf3C2",
        "outputId": "4fe810a4-f16f-405c-951b-5f404fe6b161"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(e_mask[2]) # 34"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSurvr2Lgo7k",
        "outputId": "8ea35133-f18a-47d1-9cbd-a80edca246ad"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feed src_input, tgt_input, e_mask, d_mask to model**"
      ],
      "metadata": {
        "id": "A-8oSXdaY2US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(src_input[0].reshape(1, 150))\n",
        "print(src_input[0].reshape(1, 150).shape)\n",
        "print(tgt_input[0].reshape(1, 150))\n",
        "print(tgt_input[0].reshape(1, 150).shape)\n",
        "print(e_mask[0].reshape(1, 1, 150))\n",
        "print(e_mask[0].reshape(1, 1, 150).shape)\n",
        "print(d_mask[0].reshape(1, 150, 150))\n",
        "print(d_mask[0].reshape(1, 150, 150).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUIdK-NmPz_M",
        "outputId": "c32caa2a-e6d1-4dc7-eda8-76443e89c689"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   1, 1960,   74,  128,  974,  146,    9,  418,  127,   41,  404,  817,\n",
            "            2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0]])\n",
            "torch.Size([1, 150])\n",
            "tensor([[   1, 6509, 3475, 1785,    4,   67,   48,  396,    4,  731,   13,  933,\n",
            "         3219,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0]])\n",
            "torch.Size([1, 150])\n",
            "tensor([[[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "           True,  True,  True, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False,\n",
            "          False, False, False, False, False, False, False, False, False, False]]])\n",
            "torch.Size([1, 1, 150])\n",
            "tensor([[[ True, False, False,  ..., False, False, False],\n",
            "         [ True,  True, False,  ..., False, False, False],\n",
            "         [ True,  True,  True,  ..., False, False, False],\n",
            "         ...,\n",
            "         [ True,  True,  True,  ..., False, False, False],\n",
            "         [ True,  True,  True,  ..., False, False, False],\n",
            "         [ True,  True,  True,  ..., False, False, False]]])\n",
            "torch.Size([1, 150, 150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model(src_input[0].reshape(1, 150), tgt_input[0].reshape(1, 150), e_mask[0].reshape(1, 1, 150), d_mask[0].reshape(1, 150, 150))"
      ],
      "metadata": {
        "id": "lvkOIiJyViF3"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(logits)\n",
        "print(logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9B_GHtTLjAg",
        "outputId": "a9c20c2e-1fa6-4034-e08f-0819d094fbb4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-7.5021e+00, -1.2412e+01, -7.0736e+00,  ..., -1.2030e+01,\n",
            "          -1.2297e+01, -1.2295e+01],\n",
            "         [-6.9140e+00, -1.2693e+01, -6.5903e+00,  ..., -1.1733e+01,\n",
            "          -1.1865e+01, -1.2309e+01],\n",
            "         [-7.4816e+00, -1.4167e+01, -8.6468e+00,  ..., -1.2696e+01,\n",
            "          -1.2840e+01, -1.3195e+01],\n",
            "         ...,\n",
            "         [-7.8794e-05, -1.9599e+01, -1.3170e+01,  ..., -1.9381e+01,\n",
            "          -1.8749e+01, -1.9419e+01],\n",
            "         [-7.9033e-05, -1.9655e+01, -1.3468e+01,  ..., -1.9412e+01,\n",
            "          -1.8816e+01, -1.9467e+01],\n",
            "         [-7.8913e-05, -1.9616e+01, -1.3367e+01,  ..., -1.9321e+01,\n",
            "          -1.8779e+01, -1.9378e+01]]], grad_fn=<LogSoftmaxBackward0>)\n",
            "torch.Size([1, 150, 10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Calculate loss**"
      ],
      "metadata": {
        "id": "fsKpIZctZB7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optim.zero_grad()"
      ],
      "metadata": {
        "id": "MXoZy5ZlS8D5"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(logits.view(-1, logits.shape[-1]))\n",
        "print(logits.view(-1, logits.shape[-1]).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwp-QWBrS_m7",
        "outputId": "f2bbfa02-958b-43eb-f38d-0726da38203e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-7.5021e+00, -1.2412e+01, -7.0736e+00,  ..., -1.2030e+01,\n",
            "         -1.2297e+01, -1.2295e+01],\n",
            "        [-6.9140e+00, -1.2693e+01, -6.5903e+00,  ..., -1.1733e+01,\n",
            "         -1.1865e+01, -1.2309e+01],\n",
            "        [-7.4816e+00, -1.4167e+01, -8.6468e+00,  ..., -1.2696e+01,\n",
            "         -1.2840e+01, -1.3195e+01],\n",
            "        ...,\n",
            "        [-7.8794e-05, -1.9599e+01, -1.3170e+01,  ..., -1.9381e+01,\n",
            "         -1.8749e+01, -1.9419e+01],\n",
            "        [-7.9033e-05, -1.9655e+01, -1.3468e+01,  ..., -1.9412e+01,\n",
            "         -1.8816e+01, -1.9467e+01],\n",
            "        [-7.8913e-05, -1.9616e+01, -1.3367e+01,  ..., -1.9321e+01,\n",
            "         -1.8779e+01, -1.9378e+01]], grad_fn=<ViewBackward0>)\n",
            "torch.Size([150, 10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tgt_output[0].reshape(-1))\n",
        "print(tgt_output[0].reshape(-1).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RLoyBABTDbm",
        "outputId": "20265708-f182-43b0-db7b-5ed3ac7d218e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6509, 3475, 1785,    4,   67,   48,  396,    4,  731,   13,  933, 3219,\n",
            "           2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0])\n",
            "torch.Size([150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = criterion(\n",
        "    logits.view(-1, logits.shape[-1]),\n",
        "    tgt_output[0].reshape(-1)\n",
        ")\n",
        "loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIAy1iJ-TObX",
        "outputId": "6e4d18a4-f0a2-472d-a688-aeec162475c3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3642583191394806"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "optim.step()"
      ],
      "metadata": {
        "id": "R_bMOMlHVXqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss.backward()\n",
        "# self.optim.step()\n",
        "\n",
        "# train_losses.append(loss.item())"
      ],
      "metadata": {
        "id": "h8jql82pZCRZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference step by step"
      ],
      "metadata": {
        "id": "L7Tnz6iWVllG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **switch model to eval mode**"
      ],
      "metadata": {
        "id": "NjuLztoLVqpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaFT3-efVqLS",
        "outputId": "353b07d4-28af-4874-ed14-e4b8cf192c98"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (src_embedding): Embedding(10000, 512)\n",
              "  (tgt_embedding): Embedding(10000, 512)\n",
              "  (positional_encoder): PositionalEncoder()\n",
              "  (encoder): Encoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x EncoderLayer(\n",
              "        (layer_norm_1): LayerNormalization(\n",
              "          (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (multihead_attention): MultiheadAttention(\n",
              "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attn_softmax): Softmax(dim=-1)\n",
              "          (w_0): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (drop_out_1): Dropout(p=0.1, inplace=False)\n",
              "        (layer_norm_2): LayerNormalization(\n",
              "          (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): FeedFowardLayer(\n",
              "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (drop_out_2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm): LayerNormalization(\n",
              "      (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x DecoderLayer(\n",
              "        (layer_norm_1): LayerNormalization(\n",
              "          (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (masked_multihead_attention): MultiheadAttention(\n",
              "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attn_softmax): Softmax(dim=-1)\n",
              "          (w_0): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (drop_out_1): Dropout(p=0.1, inplace=False)\n",
              "        (layer_norm_2): LayerNormalization(\n",
              "          (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (multihead_attention): MultiheadAttention(\n",
              "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attn_softmax): Softmax(dim=-1)\n",
              "          (w_0): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (drop_out_2): Dropout(p=0.1, inplace=False)\n",
              "        (layer_norm_3): LayerNormalization(\n",
              "          (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): FeedFowardLayer(\n",
              "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (drop_out_3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm): LayerNormalization(\n",
              "      (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (output_linear): Linear(in_features=512, out_features=10000, bias=True)\n",
              "  (softmax): LogSoftmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Proprocess**"
      ],
      "metadata": {
        "id": "DRa6i9NKXsoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(f\"{cfg.ckpt_dir}/{cfg.ckpt_name}\"):\n",
        "  print(\"Loading sentencepiece tokenizer...\")\n",
        "  sp_src = spm.SentencePieceProcessor()\n",
        "  sp_tgt = spm.SentencePieceProcessor()\n",
        "  sp_src.Load(f\"{cfg.sp_dir}/{cfg.src_model_prefix}.model\")\n",
        "  sp_tgt.Load(f\"{cfg.sp_dir}/{cfg.tgt_model_prefix}.model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfLina1iX_uD",
        "outputId": "3bbabe17-9449-41b9-dd10-4209d4df326d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sentencepiece tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence = 'Tôi yêu bạn.'"
      ],
      "metadata": {
        "id": "_E1bquFqYIld"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Preprocessing input sentence...\")\n",
        "tokenized = sp_src.EncodeAsIds(input_sentence)\n",
        "tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoYXa0_HV3EH",
        "outputId": "4051200a-cfa4-42b6-8bc4-1a0a038f58fd"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing input sentence...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[49, 355, 20, 308]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_data = torch.LongTensor(\n",
        "    pad_or_truncate([cfg.sos_id] + tokenized + [cfg.eos_id], cfg.seq_len, cfg.pad_id)\n",
        ").unsqueeze(0).to(cfg.device)\n",
        "src_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrS0qiylYhdq",
        "outputId": "f092d29d-5e00-4f36-d5d4-59e79e65c899"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1,  49, 355,  20, 308,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create mask**"
      ],
      "metadata": {
        "id": "3drU6SUmY7vB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e_mask = (src_data != cfg.pad_id).unsqueeze(1).to(cfg.device) # (1, 1, L)\n",
        "e_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHRmLJmrY901",
        "outputId": "ffa99aaf-a7de-43e2-bbe6-c814bb20dbbb"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False,\n",
              "          False, False, False, False, False, False, False, False, False, False]]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Embedding + positional encoding**"
      ],
      "metadata": {
        "id": "NBo83KehcSy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Encoding input sentence...\")\n",
        "src_data = model.src_embedding(src_data)\n",
        "src_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_l0GA4accrU",
        "outputId": "d4b7dd1e-49cf-439d-a6fc-1a52a97db8ee"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding input sentence...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0171,  0.0053, -0.0175,  ...,  0.0109, -0.0197,  0.0021],\n",
              "         [ 0.0038, -0.0334,  0.0255,  ..., -0.0058,  0.0320,  0.0002],\n",
              "         [-0.0155,  0.0117,  0.0165,  ...,  0.0103, -0.0025,  0.0053],\n",
              "         ...,\n",
              "         [-0.0216, -0.0148,  0.0131,  ..., -0.0124,  0.0135,  0.0092],\n",
              "         [-0.0216, -0.0148,  0.0131,  ..., -0.0124,  0.0135,  0.0092],\n",
              "         [-0.0216, -0.0148,  0.0131,  ..., -0.0124,  0.0135,  0.0092]]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_data = model.positional_encoder(src_data)\n",
        "src_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06lultuzci1a",
        "outputId": "58320d89-ebd7-479f-d1fb-7c0a55b0c567"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3870,  1.1194, -0.3957,  ...,  1.2476, -0.4466,  1.0479],\n",
              "         [ 0.9268, -0.1862,  1.3790,  ...,  0.8686,  0.7241,  1.0046],\n",
              "         [ 0.5589, -0.0866,  1.3306,  ...,  1.2332, -0.0575,  1.1208],\n",
              "         ...,\n",
              "         [ 0.1197, -1.2419, -0.6955,  ...,  0.7183,  0.3047,  1.2071],\n",
              "         [-0.8277, -0.5062, -0.1887,  ...,  0.7183,  0.3047,  1.2071],\n",
              "         [-1.4640,  0.3774,  0.7079,  ...,  0.7183,  0.3047,  1.2071]]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Go through encoder**"
      ],
      "metadata": {
        "id": "MtLEgY1zdAns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e_output = model.encoder(src_data, e_mask) # (1, L, d_model)"
      ],
      "metadata": {
        "id": "eSbrbwxidWdF"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(e_output)\n",
        "print(e_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtXZ5qiidaNc",
        "outputId": "09d5334c-b806-4ead-f046-2c59d21e90a4"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.1970, -1.6769,  1.1399,  ..., -0.3952, -1.1380,  1.1183],\n",
            "         [-0.1228, -1.9183,  1.3894,  ..., -0.7759, -0.5548,  1.0149],\n",
            "         [-0.2277, -1.9047,  1.2152,  ..., -0.4457, -1.1053,  0.8765],\n",
            "         ...,\n",
            "         [ 0.0669, -2.1646,  1.2392,  ..., -0.5328, -0.7571,  1.0111],\n",
            "         [-0.1282, -2.0022,  1.3519,  ..., -0.5859, -0.8206,  1.0823],\n",
            "         [-0.2480, -1.8211,  1.5326,  ..., -0.6345, -0.8304,  1.1566]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "torch.Size([1, 150, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Greedy search**"
      ],
      "metadata": {
        "id": "W4nde4Erdtd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_search(e_output, e_mask):\n",
        "  last_words = torch.LongTensor([cfg.pad_id] * cfg.seq_len).to(cfg.device) # (L)\n",
        "  print(\"last_words: \\n\", last_words)\n",
        "  print(\"last_words len = \", len(last_words))\n",
        "\n",
        "  last_words[0] = cfg.sos_id # (L)\n",
        "  cur_len = 1\n",
        "  print(\"last_words: \\n\", last_words)\n",
        "  print(\"last_words len = \", len(last_words))\n",
        "\n",
        "  for i in range(cfg.seq_len):\n",
        "      print(\"============ Iter {} ============\".format(i))\n",
        "      d_mask = (last_words.unsqueeze(0) != cfg.pad_id).unsqueeze(1).to(cfg.device) # (1, 1, L)\n",
        "      nopeak_mask = torch.ones([1, cfg.seq_len, cfg.seq_len], dtype=torch.bool).to(cfg.device)  # (1, L, L)\n",
        "      nopeak_mask = torch.tril(nopeak_mask)  # (1, L, L) to triangular shape\n",
        "      d_mask = d_mask & nopeak_mask  # (1, L, L) padding false\n",
        "      print(\"d_mask: \\n\", d_mask)\n",
        "      print(\"d_mask shape: \", d_mask.shape)\n",
        "\n",
        "      tgt_embedded = model.tgt_embedding(last_words.unsqueeze(0))\n",
        "      tgt_positional_encoded = model.positional_encoder(tgt_embedded)\n",
        "      print(\"Embedded + positional_encoded last_words: \\n\", tgt_positional_encoded)\n",
        "      print(\"Embedded + positional_encoded last_words shape: \", tgt_positional_encoded.shape)\n",
        "\n",
        "      decoder_output = model.decoder(\n",
        "          tgt_positional_encoded,\n",
        "          e_output,\n",
        "          e_mask,\n",
        "          d_mask\n",
        "      ) # (1, L, d_model)\n",
        "      print(\"Decoder_output: \\n\", decoder_output)\n",
        "      print(\"Decoder_output shape: \", decoder_output.shape)\n",
        "\n",
        "      output = model.softmax(\n",
        "          model.output_linear(decoder_output)\n",
        "      ) # (1, L, trg_vocab_size)\n",
        "      print(\"Decoder_output after softmax: \\n\", output)\n",
        "      print(\"Decoder_output shape: \", output.shape)\n",
        "\n",
        "      output = torch.argmax(output, dim=-1) # (1, L)\n",
        "      print(\"Get argmax of output: \\n\", output)\n",
        "      last_word_id = output[0][i].item()\n",
        "      print(\"last_word_id: \", last_word_id)\n",
        "\n",
        "      if i < cfg.seq_len-1:\n",
        "          last_words[i+1] = last_word_id\n",
        "          cur_len += 1\n",
        "          print(\"last_words: \\n\", last_words)\n",
        "\n",
        "\n",
        "      if last_word_id == cfg.eos_id:\n",
        "          break\n",
        "\n",
        "  if last_words[-1].item() == cfg.pad_id:\n",
        "      decoded_output = last_words[1:cur_len].tolist()\n",
        "  else:\n",
        "      decoded_output = last_words[1:].tolist()\n",
        "  decoded_output = sp_tgt.decode_ids(decoded_output)\n",
        "  print(\"decoded_output: \", decoded_output)\n",
        "  return decoded_output"
      ],
      "metadata": {
        "id": "ROP7TSWCeiAx"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = greedy_search(e_output, e_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtAdBhc-eJy_",
        "outputId": "1c293834-9c47-454f-9188-68d2bd44ff78"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last_words: \n",
            " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0])\n",
            "last_words len =  150\n",
            "last_words: \n",
            " tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0])\n",
            "last_words len =  150\n",
            "============ Iter 0 ============\n",
            "d_mask: \n",
            " tensor([[[ True, False, False,  ..., False, False, False],\n",
            "         [ True, False, False,  ..., False, False, False],\n",
            "         [ True, False, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [ True, False, False,  ..., False, False, False],\n",
            "         [ True, False, False,  ..., False, False, False],\n",
            "         [ True, False, False,  ..., False, False, False]]])\n",
            "d_mask shape:  torch.Size([1, 150, 150])\n",
            "Embedded + positional_encoded last_words: \n",
            " tensor([[[-0.2822,  0.5075, -0.4465,  ...,  0.7537, -0.1813,  0.5258],\n",
            "         [ 0.6885,  0.8353,  1.0997,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         [ 0.7563, -0.0853,  1.2558,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         ...,\n",
            "         [ 0.4561, -0.6419, -0.6932,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         [-0.4913,  0.0939, -0.1865,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         [-1.1276,  0.9774,  0.7102,  ...,  0.9237,  0.2031,  1.3211]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Embedded + positional_encoded last_words shape:  torch.Size([1, 150, 512])\n",
            "Decoder_output: \n",
            " tensor([[[-2.5520, -0.1006, -1.4539,  ...,  1.1269, -0.5102, -0.8451],\n",
            "         [ 0.0506,  1.0802, -1.5365,  ...,  1.6035,  1.0041,  0.4488],\n",
            "         [ 0.2104,  1.0074, -1.5127,  ...,  1.6248,  1.0389,  0.5264],\n",
            "         ...,\n",
            "         [ 0.5962,  1.0282, -1.6567,  ...,  1.6829,  1.1075,  0.7514],\n",
            "         [ 0.4921,  1.0939, -1.6229,  ...,  1.6794,  1.0896,  0.7358],\n",
            "         [ 0.4185,  1.1777, -1.5500,  ...,  1.6780,  1.0735,  0.7225]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "Decoder_output shape:  torch.Size([1, 150, 512])\n",
            "Decoder_output after softmax: \n",
            " tensor([[[-9.7884e+00, -1.6684e+01, -8.8662e+00,  ..., -1.6342e+01,\n",
            "          -1.6295e+01, -1.6925e+01],\n",
            "         [-3.2746e-03, -1.9521e+01, -1.0423e+01,  ..., -1.9098e+01,\n",
            "          -1.8578e+01, -1.9483e+01],\n",
            "         [-1.7533e-03, -1.9808e+01, -1.0947e+01,  ..., -1.9385e+01,\n",
            "          -1.8847e+01, -1.9754e+01],\n",
            "         ...,\n",
            "         [-2.5591e-04, -2.0178e+01, -1.2296e+01,  ..., -1.9835e+01,\n",
            "          -1.9279e+01, -2.0097e+01],\n",
            "         [-2.7462e-04, -2.0167e+01, -1.2242e+01,  ..., -1.9824e+01,\n",
            "          -1.9268e+01, -2.0092e+01],\n",
            "         [-2.8690e-04, -2.0173e+01, -1.2204e+01,  ..., -1.9828e+01,\n",
            "          -1.9273e+01, -2.0102e+01]]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Decoder_output shape:  torch.Size([1, 150, 10000])\n",
            "Get argmax of output: \n",
            " tensor([[17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0]])\n",
            "last_word_id:  17\n",
            "last_words: \n",
            " tensor([ 1, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0])\n",
            "============ Iter 1 ============\n",
            "d_mask: \n",
            " tensor([[[ True, False, False,  ..., False, False, False],\n",
            "         [ True,  True, False,  ..., False, False, False],\n",
            "         [ True,  True, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [ True,  True, False,  ..., False, False, False],\n",
            "         [ True,  True, False,  ..., False, False, False],\n",
            "         [ True,  True, False,  ..., False, False, False]]])\n",
            "d_mask shape:  torch.Size([1, 150, 150])\n",
            "Embedded + positional_encoded last_words: \n",
            " tensor([[[-0.2822,  0.5075, -0.4465,  ...,  0.7537, -0.1813,  0.5258],\n",
            "         [ 1.0065,  1.0710,  1.0799,  ...,  0.8635, -0.2603,  1.4023],\n",
            "         [ 0.7563, -0.0853,  1.2558,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         ...,\n",
            "         [ 0.4561, -0.6419, -0.6932,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         [-0.4913,  0.0939, -0.1865,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         [-1.1276,  0.9774,  0.7102,  ...,  0.9237,  0.2031,  1.3211]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Embedded + positional_encoded last_words shape:  torch.Size([1, 150, 512])\n",
            "Decoder_output: \n",
            " tensor([[[-2.5520, -0.1006, -1.4539,  ...,  1.1269, -0.5102, -0.8451],\n",
            "         [-1.2687,  0.1347, -0.0934,  ...,  0.5198,  0.4793,  0.8464],\n",
            "         [ 1.0474,  1.2401, -1.1906,  ...,  1.4258,  1.1178,  1.0533],\n",
            "         ...,\n",
            "         [ 1.0794,  1.0675, -1.3271,  ...,  1.5554,  1.1680,  1.0203],\n",
            "         [ 1.0065,  1.1306, -1.2875,  ...,  1.5535,  1.1501,  1.0096],\n",
            "         [ 0.9553,  1.2013, -1.2238,  ...,  1.5559,  1.1264,  1.0026]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "Decoder_output shape:  torch.Size([1, 150, 512])\n",
            "Decoder_output after softmax: \n",
            " tensor([[[-9.7884e+00, -1.6684e+01, -8.8662e+00,  ..., -1.6342e+01,\n",
            "          -1.6295e+01, -1.6925e+01],\n",
            "         [-1.0851e+01, -1.7103e+01, -1.0322e+01,  ..., -1.6198e+01,\n",
            "          -1.5710e+01, -1.6833e+01],\n",
            "         [-1.5103e-04, -2.0574e+01, -1.3805e+01,  ..., -2.0167e+01,\n",
            "          -1.9464e+01, -2.0567e+01],\n",
            "         ...,\n",
            "         [-9.3337e-05, -2.0449e+01, -1.3846e+01,  ..., -2.0098e+01,\n",
            "          -1.9452e+01, -2.0424e+01],\n",
            "         [-9.3217e-05, -2.0447e+01, -1.3865e+01,  ..., -2.0097e+01,\n",
            "          -1.9448e+01, -2.0425e+01],\n",
            "         [-9.2264e-05, -2.0444e+01, -1.3901e+01,  ..., -2.0091e+01,\n",
            "          -1.9446e+01, -2.0420e+01]]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Decoder_output shape:  torch.Size([1, 150, 10000])\n",
            "Get argmax of output: \n",
            " tensor([[ 17, 235,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
            "last_word_id:  235\n",
            "last_words: \n",
            " tensor([  1,  17, 235,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
            "============ Iter 2 ============\n",
            "d_mask: \n",
            " tensor([[[ True, False, False,  ..., False, False, False],\n",
            "         [ True,  True, False,  ..., False, False, False],\n",
            "         [ True,  True,  True,  ..., False, False, False],\n",
            "         ...,\n",
            "         [ True,  True,  True,  ..., False, False, False],\n",
            "         [ True,  True,  True,  ..., False, False, False],\n",
            "         [ True,  True,  True,  ..., False, False, False]]])\n",
            "d_mask shape:  torch.Size([1, 150, 150])\n",
            "Embedded + positional_encoded last_words: \n",
            " tensor([[[-0.2822,  0.5075, -0.4465,  ...,  0.7537, -0.1813,  0.5258],\n",
            "         [ 1.0065,  1.0710,  1.0799,  ...,  0.8635, -0.2603,  1.4023],\n",
            "         [ 0.7720, -0.9168,  0.4458,  ...,  1.2573,  0.0468,  0.9404],\n",
            "         ...,\n",
            "         [ 0.4561, -0.6419, -0.6932,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         [-0.4913,  0.0939, -0.1865,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         [-1.1276,  0.9774,  0.7102,  ...,  0.9237,  0.2031,  1.3211]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Embedded + positional_encoded last_words shape:  torch.Size([1, 150, 512])\n",
            "Decoder_output: \n",
            " tensor([[[-2.5520, -0.1006, -1.4539,  ...,  1.1269, -0.5102, -0.8451],\n",
            "         [-1.2687,  0.1347, -0.0934,  ...,  0.5198,  0.4793,  0.8464],\n",
            "         [-0.6568,  0.5491, -0.7791,  ...,  0.9892,  0.1994,  0.4487],\n",
            "         ...,\n",
            "         [ 1.2077,  1.1686, -1.2994,  ...,  1.7225,  1.2177,  1.1138],\n",
            "         [ 1.1274,  1.2320, -1.2593,  ...,  1.7123,  1.2032,  1.0996],\n",
            "         [ 1.0640,  1.2988, -1.1905,  ...,  1.6937,  1.1697,  1.0823]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "Decoder_output shape:  torch.Size([1, 150, 512])\n",
            "Decoder_output after softmax: \n",
            " tensor([[[-9.7884e+00, -1.6684e+01, -8.8662e+00,  ..., -1.6342e+01,\n",
            "          -1.6295e+01, -1.6925e+01],\n",
            "         [-1.0851e+01, -1.7103e+01, -1.0322e+01,  ..., -1.6198e+01,\n",
            "          -1.5710e+01, -1.6833e+01],\n",
            "         [-9.1901e+00, -1.8093e+01, -1.0811e+01,  ..., -1.7331e+01,\n",
            "          -1.6868e+01, -1.8145e+01],\n",
            "         ...,\n",
            "         [-8.5708e-05, -2.0648e+01, -1.3304e+01,  ..., -2.0349e+01,\n",
            "          -1.9728e+01, -2.0584e+01],\n",
            "         [-8.5231e-05, -2.0651e+01, -1.3329e+01,  ..., -2.0353e+01,\n",
            "          -1.9731e+01, -2.0590e+01],\n",
            "         [-8.4397e-05, -2.0651e+01, -1.3370e+01,  ..., -2.0344e+01,\n",
            "          -1.9729e+01, -2.0591e+01]]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Decoder_output shape:  torch.Size([1, 150, 10000])\n",
            "Get argmax of output: \n",
            " tensor([[ 17, 235,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
            "last_word_id:  21\n",
            "last_words: \n",
            " tensor([  1,  17, 235,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
            "============ Iter 3 ============\n",
            "d_mask: \n",
            " tensor([[[ True, False, False,  ..., False, False, False],\n",
            "         [ True,  True, False,  ..., False, False, False],\n",
            "         [ True,  True,  True,  ..., False, False, False],\n",
            "         ...,\n",
            "         [ True,  True,  True,  ..., False, False, False],\n",
            "         [ True,  True,  True,  ..., False, False, False],\n",
            "         [ True,  True,  True,  ..., False, False, False]]])\n",
            "d_mask shape:  torch.Size([1, 150, 150])\n",
            "Embedded + positional_encoded last_words: \n",
            " tensor([[[-0.2822,  0.5075, -0.4465,  ...,  0.7537, -0.1813,  0.5258],\n",
            "         [ 1.0065,  1.0710,  1.0799,  ...,  0.8635, -0.2603,  1.4023],\n",
            "         [ 0.7720, -0.9168,  0.4458,  ...,  1.2573,  0.0468,  0.9404],\n",
            "         ...,\n",
            "         [ 0.4561, -0.6419, -0.6932,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         [-0.4913,  0.0939, -0.1865,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         [-1.1276,  0.9774,  0.7102,  ...,  0.9237,  0.2031,  1.3211]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Embedded + positional_encoded last_words shape:  torch.Size([1, 150, 512])\n",
            "Decoder_output: \n",
            " tensor([[[-2.5520, -0.1006, -1.4539,  ...,  1.1269, -0.5102, -0.8451],\n",
            "         [-1.2687,  0.1347, -0.0934,  ...,  0.5198,  0.4793,  0.8464],\n",
            "         [-0.6568,  0.5491, -0.7791,  ...,  0.9892,  0.1994,  0.4487],\n",
            "         ...,\n",
            "         [ 1.2087,  1.2284, -1.1390,  ...,  1.6936,  1.1629,  1.0955],\n",
            "         [ 1.1305,  1.2908, -1.1063,  ...,  1.6841,  1.1536,  1.0824],\n",
            "         [ 1.0688,  1.3511, -1.0470,  ...,  1.6763,  1.1333,  1.0671]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "Decoder_output shape:  torch.Size([1, 150, 512])\n",
            "Decoder_output after softmax: \n",
            " tensor([[[-9.7884e+00, -1.6684e+01, -8.8662e+00,  ..., -1.6342e+01,\n",
            "          -1.6295e+01, -1.6925e+01],\n",
            "         [-1.0851e+01, -1.7103e+01, -1.0322e+01,  ..., -1.6198e+01,\n",
            "          -1.5710e+01, -1.6833e+01],\n",
            "         [-9.1901e+00, -1.8093e+01, -1.0811e+01,  ..., -1.7331e+01,\n",
            "          -1.6868e+01, -1.8145e+01],\n",
            "         ...,\n",
            "         [-7.6887e-05, -2.0653e+01, -1.3221e+01,  ..., -2.0283e+01,\n",
            "          -1.9706e+01, -2.0518e+01],\n",
            "         [-7.7364e-05, -2.0659e+01, -1.3226e+01,  ..., -2.0289e+01,\n",
            "          -1.9712e+01, -2.0526e+01],\n",
            "         [-7.7841e-05, -2.0661e+01, -1.3247e+01,  ..., -2.0284e+01,\n",
            "          -1.9713e+01, -2.0530e+01]]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Decoder_output shape:  torch.Size([1, 150, 10000])\n",
            "Get argmax of output: \n",
            " tensor([[ 17, 235,  21,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
            "last_word_id:  7\n",
            "last_words: \n",
            " tensor([  1,  17, 235,  21,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
            "============ Iter 4 ============\n",
            "d_mask: \n",
            " tensor([[[ True, False, False,  ..., False, False, False],\n",
            "         [ True,  True, False,  ..., False, False, False],\n",
            "         [ True,  True,  True,  ..., False, False, False],\n",
            "         ...,\n",
            "         [ True,  True,  True,  ..., False, False, False],\n",
            "         [ True,  True,  True,  ..., False, False, False],\n",
            "         [ True,  True,  True,  ..., False, False, False]]])\n",
            "d_mask shape:  torch.Size([1, 150, 150])\n",
            "Embedded + positional_encoded last_words: \n",
            " tensor([[[-0.2822,  0.5075, -0.4465,  ...,  0.7537, -0.1813,  0.5258],\n",
            "         [ 1.0065,  1.0710,  1.0799,  ...,  0.8635, -0.2603,  1.4023],\n",
            "         [ 0.7720, -0.9168,  0.4458,  ...,  1.2573,  0.0468,  0.9404],\n",
            "         ...,\n",
            "         [ 0.4561, -0.6419, -0.6932,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         [-0.4913,  0.0939, -0.1865,  ...,  0.9237,  0.2031,  1.3211],\n",
            "         [-1.1276,  0.9774,  0.7102,  ...,  0.9237,  0.2031,  1.3211]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Embedded + positional_encoded last_words shape:  torch.Size([1, 150, 512])\n",
            "Decoder_output: \n",
            " tensor([[[-2.5520, -0.1006, -1.4539,  ...,  1.1269, -0.5102, -0.8451],\n",
            "         [-1.2687,  0.1347, -0.0934,  ...,  0.5198,  0.4793,  0.8464],\n",
            "         [-0.6568,  0.5491, -0.7791,  ...,  0.9892,  0.1994,  0.4487],\n",
            "         ...,\n",
            "         [ 1.2672,  1.3115, -1.1467,  ...,  1.7251,  1.1174,  1.1470],\n",
            "         [ 1.2025,  1.3640, -1.1210,  ...,  1.7175,  1.1100,  1.1370],\n",
            "         [ 1.1530,  1.4205, -1.0715,  ...,  1.7111,  1.0968,  1.1289]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "Decoder_output shape:  torch.Size([1, 150, 512])\n",
            "Decoder_output after softmax: \n",
            " tensor([[[-9.7884e+00, -1.6684e+01, -8.8662e+00,  ..., -1.6342e+01,\n",
            "          -1.6295e+01, -1.6925e+01],\n",
            "         [-1.0851e+01, -1.7103e+01, -1.0322e+01,  ..., -1.6198e+01,\n",
            "          -1.5710e+01, -1.6833e+01],\n",
            "         [-9.1901e+00, -1.8093e+01, -1.0811e+01,  ..., -1.7331e+01,\n",
            "          -1.6868e+01, -1.8145e+01],\n",
            "         ...,\n",
            "         [-6.2106e-05, -2.0307e+01, -1.3594e+01,  ..., -2.0015e+01,\n",
            "          -1.9417e+01, -2.0146e+01],\n",
            "         [-6.2464e-05, -2.0308e+01, -1.3604e+01,  ..., -2.0017e+01,\n",
            "          -1.9420e+01, -2.0150e+01],\n",
            "         [-6.2583e-05, -2.0307e+01, -1.3616e+01,  ..., -2.0014e+01,\n",
            "          -1.9421e+01, -2.0150e+01]]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Decoder_output shape:  torch.Size([1, 150, 10000])\n",
            "Get argmax of output: \n",
            " tensor([[ 17, 235,  21,   7,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
            "last_word_id:  2\n",
            "last_words: \n",
            " tensor([  1,  17, 235,  21,   7,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
            "decoded_output:  I love you .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PbsoSPw3fFzQ",
        "outputId": "54a919ff-0ba1-41e3-97d3-c538437c6447"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I love you .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Q5dJZutw0rug"
      ],
      "gpuClass": "premium",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}